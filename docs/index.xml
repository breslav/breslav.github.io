<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mikhail Breslav</title>
    <link>https://breslav.github.io/</link>
    <description>Recent content on Mikhail Breslav</description>
    <generator>Hugo</generator>
    <language>en-US</language>
    <copyright>Copyright Â© 2025, Mikhail Breslav.....</copyright>
    <lastBuildDate>Sun, 02 Mar 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://breslav.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Reviewing Linear Regression</title>
      <link>https://breslav.github.io/reviewing-linear-regression/</link>
      <pubDate>Sun, 02 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://breslav.github.io/reviewing-linear-regression/</guid>
      <description>&lt;p&gt;Linear regression is a foundational model both in the machine learning context as well as the statistics context. While at a surface level it&amp;rsquo;s generally considered a simple model, under the hood there is a fair amount of math and nuance. In this blog post I want to review the most important concepts associated with linear regression (at least from a ML point of view).&lt;/p&gt;&#xA;&lt;h3 id=&#34;core&#34;&gt;Core&lt;/h3&gt;&#xA;&lt;p&gt;Linear regression models the relationship between some dependent variable \(y\) and independent variable \(x\) as being linear. With a single independent variable it is commonly expressed as: \(y = wx + b\) or equivalently \(y = w_{0} + w_{1}x\). In multiple linear regression where we have multiple independent variables it can be expressed as: \(y = w_{0} + w_{1}x_{1} + w_{2}x_{2} + \cdots + w_{n}x_{n}\) which in vector notation is \(y = \vec{w} \cdot \vec{x}\).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Oops, Contrastive Representation Learning</title>
      <link>https://breslav.github.io/oops-contrastive-representation-learning/</link>
      <pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://breslav.github.io/oops-contrastive-representation-learning/</guid>
      <description>&lt;p&gt;Originally I wanted to focus this blog post on a vision + transformer paper known as &lt;a href=&#34;https://arxiv.org/pdf/2104.14294&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DINO&lt;/a&gt;. I quickly realized that I would need to recurse into background reading before I could understand DINO. So instead this post will be about contrastive representation learning and several other papers which will help with understanding DINO. Hence the title beginning with Oops.&lt;/p&gt;&#xA;&lt;p&gt;We&amp;rsquo;ll begin by reviewing contrastive representation learning which will set the stage for a few important papers.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vision Meets Transformers</title>
      <link>https://breslav.github.io/vision-meets-transformers/</link>
      <pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://breslav.github.io/vision-meets-transformers/</guid>
      <description>&lt;p&gt;When I began my PhD in computer vision the leading approaches of the day were models like support vector machines, probabilistic graphical models, and decision trees. Fast-forward to 2016 when I was graduating and the deep learning revolution was underway. Leading approaches were convolutional neural networks like &lt;a href=&#34;https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AlexNet&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/1409.1556&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VGG&lt;/a&gt;, and &lt;a href=&#34;https://arxiv.org/pdf/1512.03385&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ResNet&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;I had the fortune to play with CNNs for the final project of my PhD.  Specifically, I experimented with finetuning a VGG-16 CNN on a very small dataset for the task of pose estimation. The &lt;a href=&#34;https://arxiv.org/pdf/2010.11929&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;results&lt;/a&gt; weren&amp;rsquo;t very good which I think was due to a combination of having a very limited training set and targeting a domain too different from the source domain. I was working with grayscale images of moths captured in a laboratory which looked nothing like the &lt;a href=&#34;https://www.image-net.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ImageNet&lt;/a&gt; images used to train the base model.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Brief Notes on Attention Efficiency</title>
      <link>https://breslav.github.io/brief-notes-on-attention-efficiency/</link>
      <pubDate>Fri, 07 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://breslav.github.io/brief-notes-on-attention-efficiency/</guid>
      <description>&lt;p&gt;As part of my ongoing review of LLMs, I revisited the core computation performed during self attention. Like in my previous reviews, I focused on the&#xA;idea of there being three important learnable projections that map our token embeddings to queries, keys, and values which are then used to re-represent (add context to) the token embeddings. One aspect of attention that I glossed over in the past is the efficiency of this computation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Positional Embeddings are Strange</title>
      <link>https://breslav.github.io/positional-embeddings-are-strange/</link>
      <pubDate>Tue, 28 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://breslav.github.io/positional-embeddings-are-strange/</guid>
      <description>&lt;p&gt;Recently I&amp;rsquo;ve been reviewing the &amp;ldquo;basics&amp;rdquo; of large language models and decided to finally peek into the details of positional embeddings which I had ignored in the past. In this post I want to share what I&amp;rsquo;ve learned from reviewing this topic.&lt;/p&gt;&#xA;&lt;h4 id=&#34;positional-embedding-motivation&#34;&gt;Positional Embedding Motivation&lt;/h4&gt;&#xA;&lt;p&gt;In the foundational &lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Attention Is All You Need&lt;/a&gt; paper, positional embeddings are introduced as a way to add ordering information to token embeddings so that the transformer model has some way of understanding the order of the tokens. To state the somewhat obvious, we want language models to understand word order (and by extension token order) because word order impacts the semantics of what is being said.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Personal Website Reboot</title>
      <link>https://breslav.github.io/personal-website-reboot/</link>
      <pubDate>Wed, 22 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://breslav.github.io/personal-website-reboot/</guid>
      <description>&lt;p&gt;It&amp;rsquo;s 2025 and I&amp;rsquo;ve decided it was time to reboot my personal website and blog which had both gone defunct over the years. My old &lt;a href=&#34;https://valserb.wordpress.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;blog&lt;/a&gt; was started&#xA;when I began my PhD in 2010 and the last post to it was in 2018. Much of my old content centered around topics I was absorbing in grad school, like probabilistic graphical models, linear algebra, and general computing tools. A lot has happened since then and I hope to blog about some new topics that are on my mind soon, so stay tuned!&lt;/p&gt;</description>
    </item>
    <item>
      <title>CV</title>
      <link>https://breslav.github.io/cv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://breslav.github.io/cv/</guid>
      <description>&lt;p&gt;My CV can be viewed &lt;a href=&#34;https://breslav.github.io/cv_breslav.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
